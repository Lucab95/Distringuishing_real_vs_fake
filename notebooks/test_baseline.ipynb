{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx \n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from utils.TripletDataset import TripletNetworkDataset\n",
    "from utils.SASEFE_dataset import VideoSaseFEdatasetSingle\n",
    "from networks.networks import *\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import yaml\n",
    "from utils.utils import *\n",
    "from pathlib import Path\n",
    "import random\n",
    "from PIL import Image\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from torch.utils.data import Subset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import sys\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.TripletDataset import TripletNetworkDataset\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import yaml\n",
    "from utils.utils import *\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import wandb\n",
    "import math\n",
    "from utils.AverageMeter import AverageMeter\n",
    "from utils.train_epochs import train_epoch, val_epoch, validate\n",
    "input_type= \"video\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device\n",
    "random.seed(42)\n",
    "transform = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_optim(model: torch.nn, optim: torch.optim, lr: float, decay: float):\n",
    "    if optim == \"adam\":\n",
    "        return torch.optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
    "    elif optim == \"sgd\":\n",
    "        return torch.optim.SGD(model.parameters(), lr=lr, weight_decay=decay)\n",
    "    else:\n",
    "        raise TypeError(\"Optim %s is not allowed.\" % optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"configs/template_train_baseline.yaml\"\n",
    "with open(config_path, \"r\") as stream:\n",
    "    config = yaml.safe_load(stream)\n",
    "\n",
    "# make params accessible by dot notation\n",
    "params = config[\"training_params\"]\n",
    "datamodule = config[\"datamodule\"]\n",
    "num_classes = params[\"num_classes\"]\n",
    "\n",
    "train_dataset, val_dataset, test_dataset= init_dataset(datamodule[\"dataset_dir\"],datamodule[\"n_frames\"], num_classes, test_size=5, type=datamodule[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 60, 60)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2emo = config[\"int2emo\"]\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 3, 224, 224])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(x[0][0][2].permute(1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "for key in int2emo:\n",
    "    classes.append(int2emo[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    criterion,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim,\n",
    "    step: int,\n",
    "    max_epochs: int,\n",
    "    model_name: str,\n",
    "):\n",
    "\n",
    "    prev_epoch_loss = 0.0\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=step, gamma=0.1, verbose=True\n",
    "    )\n",
    "\n",
    "    last_epoch = False\n",
    "    stop_count = 0\n",
    "\n",
    "    best_train_loss = [999, -1]\n",
    "    best_val_loss = [999, -1]\n",
    "    n_steps_per_epoch = math.ceil(len(train_loader.dataset) / train_loader.batch_size)\n",
    "    example_ct = 0\n",
    "    conf_labels = []\n",
    "    conf_pred = []\n",
    "    log_input = []\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        print(\"Start epoch #%d\" % (epoch))\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "\n",
    "        print(\"\\n\\n -- Training --\")\n",
    "        model.train()\n",
    "        for i, batch in enumerate(tqdm(train_loader, 0)):\n",
    "\n",
    "            inputs,labels = batch\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            inputs,labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "\n",
    "\n",
    "            if epoch == 1 and i == 0:\n",
    "                for one_frame in batch[0][0]:\n",
    "                    log_input.append(transform(one_frame))\n",
    "                wandb.log(\n",
    "                    {\"input_example\": [wandb.Image(image) for image in log_input]}\n",
    "                )\n",
    "                wandb.log({\"input_size\": inputs.size()})\n",
    "                # print(inputs.size())\n",
    "                print(\"logged_input\")\n",
    "                # model.conv1 = nn.Conv2d(inputs.size(dim=1), 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            if outputs.shape[-1] == 1:\n",
    "                labels = labels.unsqueeze(1)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 0:\n",
    "                print(\n",
    "                    \"Progress: {:d}/{:d}. Loss:{:.3f}\".format(\n",
    "                        i, len(train_loader), running_loss / (i + 1)\n",
    "                    )\n",
    "                )\n",
    "            example_ct += len(inputs)\n",
    "            metrics = {\n",
    "                \"train/train_loss\": loss,\n",
    "                \"train/epoch\": (i + 1 + (n_steps_per_epoch * epoch))\n",
    "                / n_steps_per_epoch,\n",
    "                \"train/example_ct\": example_ct,\n",
    "            }\n",
    "        running_loss = running_loss / len(train_loader)\n",
    "\n",
    "        if running_loss < best_train_loss[0]:\n",
    "            # keep track of best train loss\n",
    "            best_train_loss[0] = running_loss\n",
    "            best_train_loss[1] = epoch\n",
    "\n",
    "        if abs(running_loss - prev_epoch_loss) < 0.001:\n",
    "            print(\n",
    "                \"Early stopping! Epoch: {:d}, Loss: {:.3f}\".format(epoch, running_loss)\n",
    "            )\n",
    "            stop_count += 1\n",
    "            if stop_count == 3:\n",
    "                last_epoch = True\n",
    "            prev_epoch_loss = running_loss\n",
    "        else:\n",
    "            prev_epoch_loss = running_loss\n",
    "            stop_count = 0\n",
    "\n",
    "        val_loss, val_prediction, labels = validate(\n",
    "            model, val_loader, device, criterion\n",
    "        )\n",
    "        correct += (val_prediction == labels).sum().item()\n",
    "\n",
    "        val_metrics = {\n",
    "            \"val/val_loss\": val_loss,\n",
    "            \"val/val_accuracy\": correct / len(val_loader.dataset),\n",
    "        }\n",
    "        print(val_metrics)\n",
    "\n",
    "        wandb.log({**metrics, **val_metrics})\n",
    "\n",
    "        # check the loss to save best model and values for conf_matrix\n",
    "        if val_loss < best_val_loss[0]:\n",
    "            best_val_loss[0] = val_loss\n",
    "            best_val_loss[1] = epoch\n",
    "            conf_labels = labels\n",
    "            conf_pred = val_prediction\n",
    "            torch.save(\n",
    "                model.state_dict(), \"checkpoints/\" + model_name + \"_best.pt\"\n",
    "            )\n",
    "\n",
    "        # save every 3epochs\n",
    "        if epoch % 3 == 0:\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                \"checkpoints/\" + model_name + \"_epoch\" + str(epoch) + \".pt\",\n",
    "            )\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if last_epoch:\n",
    "            break\n",
    "\n",
    "    # create confusion matrix on Wandb\n",
    "    wandb.log(\n",
    "        {\n",
    "            \"conf_mat\": wandb.plot.confusion_matrix(\n",
    "                probs=None, y_true=conf_labels, preds=conf_pred, class_names=classes\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    wandb.finish()\n",
    "    return best_train_loss, best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model used: ResNet50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\luca9/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3q8val8q) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>▁█</td></tr><tr><td>train/example_ct</td><td>▁█</td></tr><tr><td>train/train_loss</td><td>█▁</td></tr><tr><td>val/val_accuracy</td><td>▁▁</td></tr><tr><td>val/val_loss</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/epoch</td><td>3.0</td></tr><tr><td>train/example_ct</td><td>7648</td></tr><tr><td>train/train_loss</td><td>0.90064</td></tr><tr><td>val/val_accuracy</td><td>0.08333</td></tr><tr><td>val/val_loss</td><td>1.35299</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ResNet50_12_ep_20</strong>: <a href=\"https://wandb.ai/lucab/Distinguish/runs/3q8val8q\" target=\"_blank\">https://wandb.ai/lucab/Distinguish/runs/3q8val8q</a><br/>Synced 6 W&B file(s), 3 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20221123_202648-3q8val8q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3q8val8q). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\luca9\\Desktop\\Thesis_final\\src\\wandb\\run-20221123_203721-2urb2w3p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/lucab/Distinguish/runs/2urb2w3p\" target=\"_blank\">ResNet50_12_ep_20</a></strong> to <a href=\"https://wandb.ai/lucab/Distinguish\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training arguments:\n",
      " {'max_epochs': 20, 'lr': 0.0001, 'decay': 0.0001, 'optim': 'adam', 'step': 5, 'size': 0, 'num_classes': 12} ResNet50 ResNet50_12\n",
      "\n",
      "Model log dir: ResNet50_12/ResNet50 \n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Start epoch #1\n",
      "\n",
      "\n",
      " -- Training --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/956 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logged_input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/956 [00:00<03:40,  4.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0/956. Loss:8.733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 103/956 [00:10<01:06, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100/956. Loss:4.401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 203/956 [00:18<01:07, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 200/956. Loss:3.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 303/956 [00:26<00:54, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 300/956. Loss:3.365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 403/956 [00:34<00:47, 11.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 400/956. Loss:3.220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 503/956 [00:42<00:35, 12.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 500/956. Loss:3.127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 603/956 [00:50<00:27, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 600/956. Loss:3.063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 703/956 [00:58<00:19, 12.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 700/956. Loss:3.015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 803/956 [01:05<00:11, 12.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 800/956. Loss:2.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 903/956 [01:13<00:04, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 900/956. Loss:2.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 956/956 [01:17<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Progress: 0/480\n",
      "Progress: 100/480\n",
      "Progress: 200/480\n",
      "Progress: 300/480\n",
      "Progress: 400/480\n",
      "{'val/val_loss': 2.2490403823554517, 'val/val_accuracy': 0.08333333333333333}\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Start epoch #2\n",
      "\n",
      "\n",
      " -- Training --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/956 [00:00<01:13, 13.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0/956. Loss:2.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 102/956 [00:08<01:09, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100/956. Loss:2.644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 202/956 [00:15<00:59, 12.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 200/956. Loss:2.645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 285/956 [00:22<00:53, 12.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22524\\1854570187.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"step\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"max_epochs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                         \u001b[0mlogdir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m                     )\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22524\\3562629287.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, criterion, train_loader, val_loader, optimizer, step, max_epochs, model_name)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\luca9\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\luca9\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\luca9\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\luca9\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    151\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                    \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                    maximize=group['maximize'])\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\luca9\\miniconda3\\envs\\ml\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m def adamw(params: List[Tensor],\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for net in config[\"models\"]:\n",
    "        # initialize the modelsource            \n",
    "        model = init_model(net, num_classes, device, embeddings_size=512)\n",
    "        model.to(device)\n",
    "        # model.load_state_dict(torch.load(\"models/best_model.pt\"))\n",
    "        img_name = net+\"_\"+str(num_classes)\n",
    "\n",
    "        # We define a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "        wandb_name = (img_name + \"_ep_\" + str(params[\"max_epochs\"]))\n",
    "        wandb.init(\n",
    "            # Set the project where this run will be logged\n",
    "            project=\"Distinguish\",\n",
    "            name=f\"{wandb_name}\",\n",
    "            # Track hyperparameters and run metadata\n",
    "            config={\n",
    "                \"learning_rate\": params[\"lr\"],\n",
    "                \"model\": net,\n",
    "                \"dataset_size\": params[\"size\"],\n",
    "                \"image_src\": img_name,\n",
    "                \"epochs\": params[\"max_epochs\"],\n",
    "            },\n",
    "        )\n",
    "        # Folder to save\n",
    "        logdir = img_name+\"/\"+net\n",
    "        print(\"\\n Training arguments:\\n\", params, net, img_name)\n",
    "        print(\"\\nModel log dir:\", logdir, \"\\n\")\n",
    "\n",
    "        optim = init_optim(model, params[\"optim\"], params[\"lr\"], params[\"decay\"])\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "            \n",
    "\n",
    "        train_dataset, val_dataset, test_dataset,  = init_dataset(datamodule[\"dataset_dir\"], datamodule[\"n_frames\"], n_classes=num_classes, test_size=10, type=datamodule[\"type\"])\n",
    "        int2emo = config[\"int2emo\"]\n",
    "        train_frames=[]\n",
    "        val_frames=[]\n",
    "        for video, label in train_dataset:\n",
    "            for vid in video:\n",
    "                train_frames.append([vid,label])\n",
    "\n",
    "        for video, label in val_dataset:\n",
    "            for vid in video:\n",
    "                val_frames.append([vid,label])\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_frames, batch_size=4, shuffle=False)\n",
    "        val_loader = torch.utils.data.DataLoader(val_frames, batch_size=1, shuffle=False)\n",
    "        # create path to save checkpoints\n",
    "        if not os.path.exists(\"checkpoints/\" + img_name):\n",
    "            os.mkdir(\"checkpoints/\" + img_name)\n",
    "        #classifyer part\n",
    "        train_loss, val_loss = train(\n",
    "                        model,\n",
    "                        criterion,\n",
    "                        train_loader,\n",
    "                        val_loader,\n",
    "                        optim,\n",
    "                        params[\"step\"],\n",
    "                        params[\"max_epochs\"],\n",
    "                        logdir,\n",
    "                    )\n",
    "\n",
    "        print(\"Best train loss:\", train_loss)\n",
    "        print(\"Best val loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, epoch, log_interval=10, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bdb3465f43f7d16caa905e3d914a6bad88d39cba4b7b03ec8828b71d149d992"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
